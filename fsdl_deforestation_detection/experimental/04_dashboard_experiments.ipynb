{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dashboard experiments\n",
    "---\n",
    "\n",
    "Just a notebook with some modelling and data visualization experiments so as to adequately develop the dashboard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from functools import partial\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from fastai.vision.all import (\n",
    "    load_learner, \n",
    "    Normalize, \n",
    "    imagenet_stats, \n",
    "    DataBlock, \n",
    "    ImageBlock,\n",
    "    MultiCategoryBlock,\n",
    "    RandomSplitter,\n",
    "    ColReader,\n",
    "    Resize,\n",
    "    aug_transforms,\n",
    "    MixUp,\n",
    "    cnn_learner,\n",
    "    resnet50\n",
    ")\n",
    "from fastai.metrics import accuracy_multi, FBetaMulti\n",
    "import torch\n",
    "from torchviz import make_dot\n",
    "from skimage.io import imread\n",
    "from PIL import Image\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import colorlover as cl\n",
    "from google.cloud import storage, bigquery\n",
    "import io\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../data/\")\n",
    "import data_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"../modeling/\"\n",
    "DATA_PATH = \"/Users/andrecnf/Documents/datasets/fsdl/\"\n",
    "img_path = \"planet/planet/train-jpg/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_colors = cl.scales['8']['div']['RdYlGn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_learner(f\"{MODEL_PATH}resnet50-128.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model.eval()\n",
    "torch.no_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model.dls.splits[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model.dls.splits[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.dls[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = imread(f\"{DATA_PATH}widsdatathon2019/leaderboard_holdout_data/img_000012018.jpg\")\n",
    "sample_name = \"train_0\"\n",
    "img = imread(f\"{DATA_PATH}{img_path}{sample_name}.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_paths = glob(f\"{DATA_PATH}widsdatathon2019/leaderboard_holdout_data/*.jpg\")\n",
    "file_paths = sorted(glob(f\"{DATA_PATH}{img_path}*.jpg\"))\n",
    "file_paths[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [file_path.split(\"/\")[-1] for file_path in file_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 100\n",
    "imgs = np.empty(shape=(0, 0, 0, 0))\n",
    "count = 0\n",
    "for i in tqdm(range(n_samples)):\n",
    "    img = imread(file_paths[i])\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    if count == 0:\n",
    "        imgs = img\n",
    "    else:\n",
    "        imgs = np.concatenate((imgs, img))\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = list()\n",
    "for i in tqdm(range(n_samples)):\n",
    "    img_pred = model.predict(imgs[i])[1]\n",
    "    pred.append(img_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_and_preprocess_image(img_path):\n",
    "#     img = imread(file_paths[i])\n",
    "#     img = np.expand_dims(img, axis=0)\n",
    "#     return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from joblib import Parallel, delayed\n",
    "# list_of_images = Parallel(n_jobs=3)(delayed(load_and_preprocess_image)(img_path) for img_path in tqdm(file_paths))\n",
    "# list_of_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.predict(imgs)  # Can't directly use predict on multiple images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.data.add_test(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This doesn't seem to change the images at all, but I'm keeping it\n",
    "# for sanity sake, as we want images to have the same normalization\n",
    "# as during training\n",
    "imgs = Normalize.from_stats(*imagenet_stats)(imgs)\n",
    "imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = torch.from_numpy(imgs)\n",
    "imgs = imgs.permute((0, 3, 1, 2))\n",
    "imgs = imgs.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_logits = model.model(imgs)\n",
    "pred_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_dot(pred_logits.mean(), params=dict(model.model.named_parameters()))\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.save?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_proba = torch.sigmoid(pred_logits)\n",
    "pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = torch.round(pred_proba)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = pd.read_csv(f\"{DATA_PATH}planet/planet/train_classes.csv\")\n",
    "labels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df.sort_values(\"image_name\", inplace=True)\n",
    "labels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = data_utils.encode_tags(labels_df, drop_tags_col=True)\n",
    "labels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels_df.to_csv(f\"{DATA_PATH}planet/planet/train_classes_ohe.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels_df.iloc[:n_samples, 1:].values\n",
    "labels = torch.from_numpy(labels)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred == labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = float(accuracy_multi(inp=pred_logits, targ=labels, thresh=0.2))\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fbeta = FBetaMulti(beta=2, average=\"samples\", thresh=0.2)(preds=pred, targs=labels)\n",
    "fbeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = pd.read_csv(f\"{DATA_PATH}planet/planet/train_classes.csv\")\n",
    "labels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(size=224,bs=64,data_df=labels_df):\n",
    "    dblock = DataBlock(blocks=(ImageBlock, MultiCategoryBlock),\n",
    "                       splitter=RandomSplitter(seed=42),\n",
    "                       get_x=ColReader(0, pref=f\"{DATA_PATH}{img_path}\", suff=\".jpg\"),\n",
    "                       get_y=ColReader(1, label_delim=\" \"),\n",
    "                       item_tfms = Resize(size),\n",
    "                       batch_tfms = [*aug_transforms(flip_vert=True, max_lighting=0.1, max_zoom=1.05, max_warp=0.),\n",
    "                                     Normalize.from_stats(*imagenet_stats)]\n",
    "                      )\n",
    "    return dblock.dataloaders(data_df,bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = get_data(128, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dls.splits[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls.splits[1] == model.dls.splits[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [partial(accuracy_multi, thresh=0.2), FBetaMulti(beta=2, average='samples', thresh=0.2)]\n",
    "cbs = [MixUp]\n",
    "learn = cnn_learner(dls, resnet50, metrics=metrics, cbs=cbs).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model = model.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_proba, pred = learn.get_preds(ds_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc *= 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color = perf_colors[int(max((acc/100)*len(perf_colors)-1, 0))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(go.Indicator(\n",
    "    mode=\"gauge+number\",\n",
    "    value=acc,\n",
    "    domain=dict(x=[0, 1], y=[0, 1]),\n",
    "    gauge=dict(\n",
    "        axis=dict(range=[0, 100]),\n",
    "        bar=dict(\n",
    "            thickness=1,\n",
    "            color=color\n",
    "        )\n",
    "    ),\n",
    "    title=dict(text=\"Accuracy\")))\n",
    "fig.update_layout(margin=dict(l=25, r=40, b=0, t=0, pad=0), height=380)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, tag in enumerate(data_utils.TAGS):\n",
    "    fig.data[i].name = tag\n",
    "    fig.data[i].hovertemplate = fig.data[i].hovertemplate.replace(str(i), tag)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, tag in enumerate(data_utils.TAGS):\n",
    "    fig.data[i].name = tag\n",
    "    fig.data[i].hovertemplate = fig.data[i].hovertemplate.replace(str(i), tag)\n",
    "fig.update_layout(margin=dict(l=0, r=0, b=0, t=0, pad=0))\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(go.Indicator(\n",
    "    mode=\"number\",\n",
    "    value=len(labels_df),\n",
    "    title=dict(text=\"Samples\")\n",
    "))\n",
    "fig.update_layout(margin=dict(l=0, r=0, b=0, t=0, pad=0), height=150)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_flat = np.empty((imgs.shape[1], imgs.shape[0] * imgs.shape[2] * imgs.shape[3]))\n",
    "for i in range(imgs.shape[1]):\n",
    "    imgs_flat[i, :] = imgs[:, i, :, :].reshape((-1)).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# px.histogram(imgs_flat)  # This would take too long to run; it's better to calculate the data manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_min = int(np.min(imgs_flat))\n",
    "pixel_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_max = int(np.max(imgs_flat))\n",
    "pixel_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [i for i in range(pixel_min, pixel_max, 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.empty((imgs_flat.shape[0], len(bins)-1))\n",
    "for i in range(imgs_flat.shape[0]):\n",
    "    y[i, :], _ = np.histogram(imgs_flat[i], bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_centers = list()\n",
    "for i in range(len(bins) - 1):\n",
    "    bin_centers.append((bins[i] + bins[i+1]) / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(bin_centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixels_df = pd.DataFrame(dict(pixel_value=bin_centers, blue=y[2], red=y[0], green=y[1]))\n",
    "pixels_df.set_index(\"pixel_value\", inplace=True)\n",
    "pixels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(pixels_df, title=\"Distribution of pixel values per channel\")\n",
    "fig.update_layout(\n",
    "    yaxis_title=\"count\",\n",
    "    margin=dict(l=0, r=0, b=0, t=50, pad=0), \n",
    "    height=300\n",
    ")\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading from cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/Users/andrecnf/fsdl-305310-c35340ed449c.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_client = storage.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = \"planet_amazon\"\n",
    "bucket = storage_client.bucket(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = bucket.get_blob(\"train_classes.csv\")\n",
    "blob = blob.download_as_string()\n",
    "blob = blob.decode('utf-8')\n",
    "blob = io.StringIO(blob)\n",
    "pd.read_csv(blob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = bucket.get_blob(\"train-jpg/train_0.jpg\")\n",
    "blob = blob.download_as_bytes()\n",
    "blob = io.BytesIO(blob)\n",
    "imread(blob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_list = storage_client.list_blobs(\"wids_oil_palm\")\n",
    "files_list = [f.name.split(\"/\")[-1].split(\".\")[0] for f in files_list if \".jpg\" in f.name]\n",
    "files_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_gbq(\"SELECT * FROM `fsdl-305310.deforestation_data.planet_labels`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "user_id = 42\n",
    "image_id = 50\n",
    "test_data = dict(\n",
    "    user_id=user_id,\n",
    "    ts=datetime.now(),\n",
    "    image_id=image_id,\n",
    "    user_feedback_positive=1,\n",
    "    user_comment=\"Good job üëç\",\n",
    "    output_agriculture=0,\n",
    "    output_artisinal_mine=0,\n",
    "    output_bare_ground=0,\n",
    "    output_blooming=0,\n",
    "    output_blow_down=0,\n",
    "    output_clear=0,\n",
    "    output_cloudy=0,\n",
    "    output_conventional_mine=0,\n",
    "    output_cultivation=0,\n",
    "    output_habitation=0,\n",
    "    output_haze=0,\n",
    "    output_partly_cloudy=0,\n",
    "    output_primary=0,\n",
    "    output_road=0,\n",
    "    output_selective_logging=0,\n",
    "    output_slash_burn=0,\n",
    "    output_water=0,\n",
    ")\n",
    "test_df = pd.Series(test_data).to_frame().transpose()\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.user_id = test_df.user_id.astype(int)\n",
    "# test_df.ts = test_df.ts.apply(lambda x: x.timestamp())\n",
    "test_df.image_id = test_df.image_id.astype(int)\n",
    "test_df.user_feedback_positive = test_df.user_feedback_positive.astype(bool)\n",
    "test_df.user_comment = test_df.user_comment.astype(str)\n",
    "test_df.output_agriculture = test_df.output_agriculture.astype(bool)\n",
    "test_df.output_artisinal_mine = test_df.output_artisinal_mine.astype(bool)\n",
    "test_df.output_bare_ground = test_df.output_bare_ground.astype(bool)\n",
    "test_df.output_blooming = test_df.output_blooming.astype(bool)\n",
    "test_df.output_blow_down = test_df.output_blow_down.astype(bool)\n",
    "test_df.output_clear = test_df.output_clear.astype(bool)\n",
    "test_df.output_cloudy = test_df.output_cloudy.astype(bool)\n",
    "test_df.output_conventional_mine = test_df.output_conventional_mine.astype(bool)\n",
    "test_df.output_cultivation = test_df.output_cultivation.astype(bool)\n",
    "test_df.output_habitation = test_df.output_habitation.astype(bool)\n",
    "test_df.output_haze = test_df.output_haze.astype(bool)\n",
    "test_df.output_partly_cloudy = test_df.output_partly_cloudy.astype(bool)\n",
    "test_df.output_primary = test_df.output_primary.astype(bool)\n",
    "test_df.output_road = test_df.output_road.astype(bool)\n",
    "test_df.output_selective_logging = test_df.output_selective_logging.astype(bool)\n",
    "test_df.output_slash_burn = test_df.output_slash_burn.astype(bool)\n",
    "test_df.output_water = test_df.output_water.astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_gbq import schema\n",
    "schema.generate_bq_schema(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_gbq(\"user_data.playground_uploads\", if_exists=\"append\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_name = \"train_0\"\n",
    "img = imread(f\"{DATA_PATH}{img_path}{sample_name}.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = \"playground_images\"\n",
    "bucket = storage_client.bucket(bucket_name)\n",
    "blob = bucket.blob(\"1.jpg\")\n",
    "f = io.BytesIO()\n",
    "pil_img = Image.fromarray(img)\n",
    "pil_img.save(f, \"jpeg\")\n",
    "pil_img.close()\n",
    "blob.upload_from_string(f.getvalue(), content_type=\"image/jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bq_client = bigquery.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = 42\n",
    "image_id = 50\n",
    "dml_statement = (\n",
    "    \"DELETE user_data.playground_uploads \"\n",
    "    f\"WHERE (user_id = {user_id} AND image_id = {image_id})\"\n",
    ")\n",
    "query_job = bq_client.query(dml_statement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4dc2c7df4b65d5250f54df024531f188fe86bc29b0c36232640601d4d17bba37"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('fsdl-deforestation-detection-RY4tAb0K-py3.7': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}