# -*- coding: utf-8 -*-
"""FSDL_Final_Model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KSWPtz-YahCncbVoaW0tQ7nUG1pEEmWP

# FSDL Project
This Notebook is used to train a ResNet-50 model on Amazon Planet Dataset (MultiLabel Classification Problem)

Used Fast AI for eaiser training and inference rather than PyTorch or Tensorflow

## Load Dataset into the Drive using Kaggle API

Follow Kaggle API instruction to download the kaggle.json file and unzip the files in the current directory
"""

! pip install -Uq kaggle
! pip install -Uq fastai==2.2.5

from google.colab import files 
files.upload()

! mkdir ~/.kaggle
! cp kaggle.json ~/.kaggle/
! chmod 600 ~/.kaggle/kaggle.json

! kaggle datasets download nikitarom/planets-dataset

!unzip planets-dataset.zip

"""## Loading and Visualizing Dataset"""

from fastai.vision.all import *
path = Path('./planet/planet')

path.ls()

train_df = pd.read_csv(path/'train_classes.csv')
train_df

def get_data(size=224,bs=64,data_df=train_df):
    dblock = DataBlock(blocks=(ImageBlock, MultiCategoryBlock),
                       splitter=RandomSplitter(seed=42),
                       get_x=ColReader(0, pref=f'{path}/train-jpg/', suff='.jpg'),
                       get_y=ColReader(1, label_delim=' '),
                       item_tfms = Resize(size),
                       batch_tfms = [*aug_transforms(flip_vert=True, max_lighting=0.1, max_zoom=1.05, max_warp=0.),
                                     Normalize.from_stats(*imagenet_stats)]
                      )
    return dblock.dataloaders(data_df,bs=bs)

dls = get_data(128,256)

dls.show_batch()

"""## Train & Save ResNet-50 Model"""

metrics = [partial(accuracy_multi, thresh=0.2), FBetaMulti(beta=2, average='samples', thresh=0.2)]
cbs = [MixUp]

learn = cnn_learner(dls, resnet50, metrics=metrics, cbs=cbs).to_fp16()
learn.lr_find()

learn.fine_tune(6, base_lr=2e-2, freeze_epochs=4)

learn.save('resnet50-128')

"""## Results of the Model"""

learn.show_results()

"""## Prediction and Inference of the Model"""

learn.export() # if we want .pkl file for proper end to end deployment (file will be saved as export.pkl)

#inference = learn.load('resnet50-128')

additional_test_path = Path('test-jpg-additional/test-jpg-additional')
test_path = Path('planet/planet/test-jpg')
submission_df = pd.read_csv(path/'sample_submission.csv')
testing_path = (submission_df['image_name'] + '.jpg').apply(lambda x: test_path/x if x.startswith('test') else additional_test_path/x)

def prediction(filename='submission.csv', tta=False):
    tst_dl = learn.dls.test_dl(testing_path)
    if tta:
        predictions = learn.tta(dl = tst_dl)
    else:
        predictions = learn.get_preds(dl = tst_dl)
    predlist = [' '.join(learn.dls.vocab[i]) for i in (predictions[0] > 0.2)]

    df = submission_df
    df['tags'] = predlist

    df.to_csv(filename, index=False)
    return df

prediction('submission_tta.csv', tta=True)

